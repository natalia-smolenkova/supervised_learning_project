Проект: Обучение с учителем — Классификация с учётом дисбаланса классов
Описание проекта
В проекте поставлена цель — создать модель машинного обучения для бинарной классификации, которая достигает необходимого уровня метрики F1 ≥ 0.59. Основное внимание уделено обработке дисбаланса классов и корректной подготовке исходных данных.

Постановка задачи
Создать и обучить модель бинарной классификации на основании исторических данных при наличии выраженного дисбаланса классов (примерно 80:20). Основная метрика оценки — F1- score, дополнительная — AUC-ROC. Задача решалась на реальном датасете, в котором были пропуски и неинформативные признаки.

Характеристики данных
 	Пропуски были обнаружены и проанализированы (до 10% по некоторым признакам)
 	Пропуски были удалены, чтобы избежать ухудшения качества модели или переобучения при заполнении медианой/средним
 	Неиспользуемые для предсказания столбцы удалены
 	Категориальные признаки закодированы для использования в моделях
 	Разделение данных: обучающая (60%), валидационная (20%), тестовая (20%) выборки

Использованные модели
 	Дерево решений: обучение и подбор гиперпараметров
 	Случайный лес: обучение, подбор гиперпараметров и борьба с дисбалансом классов (методы: увеличение выборки и class_weight)

Решение проблемы дисбаланса
 	Сделано сравнение подходов: увеличение меньшего класса, использование параметра class_weight
 	Модели тестировались с балансировкой и без балансировки

Результаты

Модель	Балансировка	F1-score	AUC-ROC
Дерево решений	увеличение + веса	< 0.59	—
Случайный лес	увеличение + веса	0.60	0.86
 
Итоговые метрики на тестовой выборке:

 	F1-score: 0.60 (соответствует минимальному требованию ≥ 0.59)
 	AUC-ROC: 0.86 (близко к значению на валидационной выборке, что указывает на отсутствие переобучения)

Выводы
В проекте создана и оптимизирована модель случайного леса для задачи бинарной классификации с дисбалансом классов. Было установлено, что удаление пропусков не повлияло существенно на результат, балансировка классов помогла улучшить метрики, а случайный лес превзошёл дерево решений по F1 и AUC-ROC на тестовой выборке. Итоговая F1
= 0.60 показывает достаточный уровень качества для задачи.

Модель демонстрирует хорошую обобщающую способность, так как метрики на валидационной и тестовой выборках близки друг к другу, что указывает на отсутствие переобучения.

Этапы работы

1.	Подготовка данных
 	Загрузка и исследовательский анализ данных
 	Обработка пропущенных значений (удаление при объёме пропусков до 10%)
 	Удаление неиспользуемых столбцов
 	Кодирование категориальных признаков
 	Разделение датасета на обучающую (60%), валидационную (20%) и тестовую (20%) выборки

2.	Обучение и подбор гиперпараметров
 	Обучение модели дерева решений на обучающей выборке
 	Обучение модели случайного леса на обучающей выборке
 	Подбор оптимальных гиперпараметров с использованием валидационной выборки
 	Оценка качества моделей на валидационной выборке

3.	Решение проблемы дисбаланса классов
 	Анализ соотношения классов (80:20)
 	Применение метода увеличения выборки для меньшего класса
 	Использование параметра class_weight для взвешивания классов
 	Сравнение результатов разных подходов
 
4.	Финальное тестирование
 	Выбор лучшей модели (случайный лес)
 	Тестирование на тестовой выборке
 	Получение финальных метрик (F1 = 0.60, AUC-ROC = 0.86)

